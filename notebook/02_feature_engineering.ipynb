{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07d41067",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2640e8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9b05f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (31030, 17)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(r'../data/zomato.csv').sample(frac=0.6, random_state=42)\n",
    "print(f\"Original dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8107632a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MISSING VALUES ANALYSIS \n",
      "                             Missing_Count  Missing_Percentage\n",
      "dish_liked                           16866           54.353851\n",
      "rate                                  4671           15.053174\n",
      "phone                                  746            2.404125\n",
      "approx_cost(for two people)            205            0.660651\n",
      "rest_type                              146            0.470512\n",
      "cuisines                                31            0.099903\n",
      "location                                15            0.048340\n",
      "listed_in(type)                          0            0.000000\n",
      "menu_item                                0            0.000000\n",
      "reviews_list                             0            0.000000\n",
      "url                                      0            0.000000\n",
      "address                                  0            0.000000\n",
      "votes                                    0            0.000000\n",
      "book_table                               0            0.000000\n",
      "online_order                             0            0.000000\n",
      "name                                     0            0.000000\n",
      "listed_in(city)                          0            0.000000\n"
     ]
    }
   ],
   "source": [
    "# Missing values analysis\n",
    "print(\"\\n MISSING VALUES ANALYSIS \")\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percentage = (missing_data / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing_data,\n",
    "    'Missing_Percentage': missing_percentage\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94598309",
   "metadata": {},
   "source": [
    "### Comprehensive Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3985b0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA CLEANING SUMMARY ===\n",
      "Original NaN in rating: 4671\n",
      "Final NaN in rating: 6045\n",
      "Original NaN in cost: 205\n",
      "Final NaN in cost: 205\n"
     ]
    }
   ],
   "source": [
    "# Create a copy for feature engineering\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 1. Clean rating column\n",
    "def clean_rating(rate):\n",
    "    if pd.isna(rate) or rate in ['NEW', '-', 'nan']:\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(rate.split('/')[0])\n",
    "    except:\n",
    "        return np.nan\n",
    "df_clean['rating'] = df_clean['rate'].apply(clean_rating)\n",
    "\n",
    "# 2. Clean cost column\n",
    "def clean_cost(cost):\n",
    "    if pd.isna(cost):\n",
    "        return np.nan\n",
    "    try:\n",
    "        # Remove commas and currency symbols\n",
    "        cost_str = str(cost).replace(',', '').replace('â‚¹', '').strip()\n",
    "        return float(cost_str)\n",
    "    except:\n",
    "        return np.nan\n",
    "df_clean['cost_for_two'] = df_clean['approx_cost(for two people)'].apply(clean_cost)\n",
    "\n",
    " # 3. Clean text fields\n",
    "df_clean['location'] = df_clean['location'].fillna('Unknown Location')\n",
    "df_clean['rest_type'] = df_clean['rest_type'].fillna('Not Specified')\n",
    "df_clean['cuisines'] = df_clean['cuisines'].fillna('Not Specified')\n",
    "df_clean['dish_liked'] = df_clean['dish_liked'].fillna('')\n",
    "df_clean['phone'] = df_clean['phone'].str.replace(r'\\r\\n.*', '', regex=True).fillna('Not Available')\n",
    "\n",
    "# 4. Handle votes (should not have NaN)\n",
    "df_clean['votes'] = df_clean['votes'].fillna(0).astype(int)\n",
    "# 5. Clean binary fields\n",
    "df_clean['online_order'] = df_clean['online_order'].fillna('No')\n",
    "df_clean['book_table'] = df_clean['book_table'].fillna('No')\n",
    "\n",
    "# 6. Clean categorical fields\n",
    "df_clean['listed_in(type)'] = df_clean['listed_in(type)'].fillna('Other')\n",
    "df_clean['listed_in(city)'] = df_clean['listed_in(city)'].fillna('Other')\n",
    "\n",
    "print(\"=== DATA CLEANING SUMMARY ===\")\n",
    "print(f\"Original NaN in rating: {df['rate'].isna().sum()}\")\n",
    "print(f\"Final NaN in rating: {df_clean['rating'].isna().sum()}\")\n",
    "print(f\"Original NaN in cost: {df['approx_cost(for two people)'].isna().sum()}\")\n",
    "print(f\"Final NaN in cost: {df_clean['cost_for_two'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79018aaf",
   "metadata": {},
   "source": [
    "### Text Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8a267b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEXT PROCESSING COMPLETE ===\n",
      "Restaurants with cuisines: 30999\n",
      "Restaurants with dishes: 14164\n",
      "Combined features sample: Oriya, Fast Food Rasgulla, Mutton Kosha, Chicken Kasha, Samosa Chaat, Kheer, Veg Thali Quick Bites BTM\n"
     ]
    }
   ],
   "source": [
    "# 1. Process cuisines\n",
    "def process_cuisines(cuisines):\n",
    "    if pd.isna(cuisines) or cuisines == 'Not Specified':\n",
    "        return []\n",
    "    try:\n",
    "        return [cuisine.strip().lower() for cuisine in str(cuisines).split(',')]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "df_clean['cuisine_list'] = df_clean['cuisines'].apply(process_cuisines)\n",
    "\n",
    "# 2. Process dishes liked\n",
    "def process_dishes(dishes):\n",
    "    if pd.isna(dishes) or dishes == '':\n",
    "        return []\n",
    "    try:\n",
    "        # Handle various separators\n",
    "        dishes_str = str(dishes).replace(';', ',')\n",
    "        return [dish.strip().lower() for dish in dishes_str.split(',') if dish.strip()]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "df_clean['dish_list'] = df_clean['dish_liked'].apply(process_dishes)\n",
    "\n",
    "# 3. Create combined text features\n",
    "def create_combined_features(row):\n",
    "    \"\"\"Create combined text features for similarity\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # Add cuisines\n",
    "    if row['cuisines'] and row['cuisines'] != 'Not Specified':\n",
    "        features.append(str(row['cuisines']))\n",
    "    \n",
    "    # Add dishes\n",
    "    if row['dish_liked'] and row['dish_liked'] != '':\n",
    "        features.append(str(row['dish_liked']))\n",
    "    \n",
    "    # Add restaurant type\n",
    "    if row['rest_type'] and row['rest_type'] != 'Not Specified':\n",
    "        features.append(str(row['rest_type']))\n",
    "    \n",
    "    # Add location for context\n",
    "    if row['location'] and row['location'] != 'Unknown Location':\n",
    "        features.append(str(row['location']))\n",
    "    \n",
    "    return ' '.join(features) if features else 'no_features'\n",
    "\n",
    "df_clean['combined_features'] = df_clean.apply(create_combined_features, axis=1)\n",
    "\n",
    "# 4. Process reviews\n",
    "def extract_review_text(reviews_list):\n",
    "    if pd.isna(reviews_list) or reviews_list == '[]' or reviews_list == '':\n",
    "        return 'no_review'\n",
    "    try:\n",
    "        reviews = ast.literal_eval(str(reviews_list))\n",
    "        review_texts = []\n",
    "        for review in reviews:\n",
    "            if isinstance(review, tuple) and len(review) > 1:\n",
    "                review_texts.append(str(review[1]))\n",
    "            elif isinstance(review, str):\n",
    "                review_texts.append(review)\n",
    "        return ' '.join(review_texts) if review_texts else 'no_review'\n",
    "    except:\n",
    "        return 'no_review'\n",
    "\n",
    "df_clean['review_text'] = df_clean['reviews_list'].apply(extract_review_text)\n",
    "\n",
    "print(\"=== TEXT PROCESSING COMPLETE ===\")\n",
    "print(f\"Restaurants with cuisines: {(df_clean['cuisine_list'].apply(len) > 0).sum()}\")\n",
    "print(f\"Restaurants with dishes: {(df_clean['dish_list'].apply(len) > 0).sum()}\")\n",
    "print(f\"Combined features sample: {df_clean['combined_features'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c4b3e4",
   "metadata": {},
   "source": [
    "###  Numerical Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dab321d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NUMERICAL FEATURES COMPLETE ===\n",
      "No NaN in rating_imputed: True\n",
      "No NaN in cost_imputed: True\n",
      "Numerical features shape: (31030, 5)\n"
     ]
    }
   ],
   "source": [
    "# 1. Handle missing numerical values with proper imputation\n",
    "# Create imputers\n",
    "rating_imputer = SimpleImputer(strategy='median')\n",
    "cost_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Fit and transform\n",
    "df_clean['rating_imputed'] = rating_imputer.fit_transform(df_clean[['rating']]).flatten()\n",
    "df_clean['cost_imputed'] = cost_imputer.fit_transform(df_clean[['cost_for_two']]).flatten()\n",
    "\n",
    "# 2. Create derived features\n",
    "df_clean['log_votes'] = np.log1p(df_clean['votes'])  # Log transform votes\n",
    "df_clean['rating_votes_interaction'] = df_clean['rating_imputed'] * df_clean['log_votes']\n",
    "df_clean['cost_per_rating'] = df_clean['cost_imputed'] / (df_clean['rating_imputed'] + 0.1)\n",
    "df_clean['popularity_score'] = df_clean['rating_imputed'] * df_clean['log_votes']\n",
    "\n",
    "# 3. Create categorical numerical features\n",
    "# Binary features\n",
    "df_clean['online_order_binary'] = (df_clean['online_order'] == 'Yes').astype(int)\n",
    "df_clean['book_table_binary'] = (df_clean['book_table'] == 'Yes').astype(int)\n",
    "\n",
    "# Price categories\n",
    "def categorize_price(cost):\n",
    "    if cost <= 300:\n",
    "        return 0  # Budget\n",
    "    elif cost <= 600:\n",
    "        return 1  # Mid-range\n",
    "    elif cost <= 1200:\n",
    "        return 2  # Expensive\n",
    "    else:\n",
    "        return 3  # Premium\n",
    "\n",
    "df_clean['price_category'] = df_clean['cost_imputed'].apply(categorize_price)\n",
    "\n",
    "# Rating categories\n",
    "def categorize_rating(rating):\n",
    "    if rating < 3.0:\n",
    "        return 0  # Poor\n",
    "    elif rating < 3.5:\n",
    "        return 1  # Average\n",
    "    elif rating < 4.0:\n",
    "        return 2  # Good\n",
    "    else:\n",
    "        return 3  # Excellent\n",
    "\n",
    "df_clean['rating_category'] = df_clean['rating_imputed'].apply(categorize_rating)\n",
    "\n",
    "# 4. Scale numerical features\n",
    "feature_scaler = StandardScaler()\n",
    "numerical_columns = ['rating_imputed', 'cost_imputed', 'log_votes', \n",
    "                    'rating_votes_interaction', 'popularity_score']\n",
    "\n",
    "scaled_features = feature_scaler.fit_transform(df_clean[numerical_columns])\n",
    "scaled_df = pd.DataFrame(scaled_features, \n",
    "                        columns=[col + '_scaled' for col in numerical_columns],\n",
    "                        index=df_clean.index)\n",
    "\n",
    "# Add scaled features to main dataframe\n",
    "df_clean = pd.concat([df_clean, scaled_df], axis=1)\n",
    "\n",
    "print(\"=== NUMERICAL FEATURES COMPLETE ===\")\n",
    "print(f\"No NaN in rating_imputed: {df_clean['rating_imputed'].isna().sum() == 0}\")\n",
    "print(f\"No NaN in cost_imputed: {df_clean['cost_imputed'].isna().sum() == 0}\")\n",
    "print(f\"Numerical features shape: {scaled_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf45870",
   "metadata": {},
   "source": [
    "### Categorical Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "895b2f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CATEGORICAL ENCODING COMPLETE ===\n",
      "Location features: 76\n",
      "Restaurant type features: 65\n",
      "Cuisine features: 108\n",
      "Service features: 4\n",
      "NaNs in location_encoded: 0\n",
      "NaNs in rest_type_encoded: 0\n",
      "NaNs in cuisine_df: 0\n",
      "NaNs in service_features: 0\n"
     ]
    }
   ],
   "source": [
    "# 1. Location encoding (group less frequent locations)\n",
    "location_counts = df_clean['location'].value_counts()\n",
    "popular_locations = location_counts[location_counts >= 20].index  # Minimum 20 restaurants\n",
    "\n",
    "def group_location(location):\n",
    "    return location if location in popular_locations else 'Other_Location'\n",
    "\n",
    "df_clean['location_grouped'] = df_clean['location'].apply(group_location)\n",
    "location_encoded = pd.get_dummies(df_clean['location_grouped'], prefix='location')\n",
    "\n",
    "# 2. Restaurant type encoding\n",
    "rest_type_counts = df_clean['rest_type'].value_counts()\n",
    "popular_rest_types = rest_type_counts[rest_type_counts >= 10].index\n",
    "\n",
    "def group_rest_type(rest_type):\n",
    "    return rest_type if rest_type in popular_rest_types else 'Other_Type'\n",
    "\n",
    "df_clean['rest_type_grouped'] = df_clean['rest_type'].apply(group_rest_type)\n",
    "rest_type_encoded = pd.get_dummies(df_clean['rest_type_grouped'], prefix='rest_type')\n",
    "\n",
    "# 3. Cuisine encoding using MultiLabelBinarizer\n",
    "cuisine_encoder = MultiLabelBinarizer()\n",
    "\n",
    "# Filter out empty lists and ensure we have at least one cuisine per restaurant\n",
    "cuisine_lists_filtered = []\n",
    "for cuisine_list in df_clean['cuisine_list']:\n",
    "    if len(cuisine_list) > 0:\n",
    "        cuisine_lists_filtered.append(cuisine_list)\n",
    "    else:\n",
    "        cuisine_lists_filtered.append(['unknown'])  # Default cuisine for empty lists\n",
    "\n",
    "cuisine_encoded = cuisine_encoder.fit_transform(cuisine_lists_filtered)\n",
    "cuisine_df = pd.DataFrame(cuisine_encoded, \n",
    "                            columns=['cuisine_' + col for col in cuisine_encoder.classes_],\n",
    "                            index=df_clean.index)\n",
    "\n",
    "# 4. Service features\n",
    "service_features = df_clean[['online_order_binary', 'book_table_binary', \n",
    "                            'price_category', 'rating_category']].copy()\n",
    "\n",
    "print(\"=== CATEGORICAL ENCODING COMPLETE ===\")\n",
    "print(f\"Location features: {location_encoded.shape[1]}\")\n",
    "print(f\"Restaurant type features: {rest_type_encoded.shape[1]}\")\n",
    "print(f\"Cuisine features: {cuisine_df.shape[1]}\")\n",
    "print(f\"Service features: {service_features.shape[1]}\")\n",
    "\n",
    "# Check for NaNs\n",
    "print(f\"NaNs in location_encoded: {location_encoded.isna().sum().sum()}\")\n",
    "print(f\"NaNs in rest_type_encoded: {rest_type_encoded.isna().sum().sum()}\")\n",
    "print(f\"NaNs in cuisine_df: {cuisine_df.isna().sum().sum()}\")\n",
    "print(f\"NaNs in service_features: {service_features.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e170c75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MISSING VALUES ANALYSIS \n",
      "                                 Missing_Count  Missing_Percentage\n",
      "rating                                    6045           19.481147\n",
      "rate                                      4671           15.053174\n",
      "approx_cost(for two people)                205            0.660651\n",
      "cost_for_two                               205            0.660651\n",
      "url                                          0            0.000000\n",
      "cost_imputed                                 0            0.000000\n",
      "log_votes                                    0            0.000000\n",
      "rating_votes_interaction                     0            0.000000\n",
      "cost_per_rating                              0            0.000000\n",
      "popularity_score                             0            0.000000\n",
      "online_order_binary                          0            0.000000\n",
      "book_table_binary                            0            0.000000\n",
      "review_text                                  0            0.000000\n",
      "price_category                               0            0.000000\n",
      "rating_category                              0            0.000000\n",
      "rating_imputed_scaled                        0            0.000000\n",
      "cost_imputed_scaled                          0            0.000000\n",
      "log_votes_scaled                             0            0.000000\n",
      "rating_votes_interaction_scaled              0            0.000000\n",
      "popularity_score_scaled                      0            0.000000\n",
      "location_grouped                             0            0.000000\n",
      "rating_imputed                               0            0.000000\n",
      "dish_list                                    0            0.000000\n",
      "combined_features                            0            0.000000\n",
      "rest_type                                    0            0.000000\n",
      "name                                         0            0.000000\n",
      "online_order                                 0            0.000000\n",
      "book_table                                   0            0.000000\n",
      "votes                                        0            0.000000\n",
      "phone                                        0            0.000000\n",
      "location                                     0            0.000000\n",
      "dish_liked                                   0            0.000000\n",
      "address                                      0            0.000000\n",
      "cuisines                                     0            0.000000\n",
      "reviews_list                                 0            0.000000\n",
      "menu_item                                    0            0.000000\n",
      "listed_in(type)                              0            0.000000\n",
      "listed_in(city)                              0            0.000000\n",
      "cuisine_list                                 0            0.000000\n",
      "rest_type_grouped                            0            0.000000\n"
     ]
    }
   ],
   "source": [
    "# Missing values analysis\n",
    "print(\"\\n MISSING VALUES ANALYSIS \")\n",
    "missing_data = df_clean.isnull().sum()\n",
    "missing_percentage = (missing_data / len(df_clean)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing_data,\n",
    "    'Missing_Percentage': missing_percentage\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea13f76",
   "metadata": {},
   "source": [
    "### Text vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfd8c7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEXT VECTORIZATION COMPLETE ===\n",
      "Combined TF-IDF features: 50\n",
      "Review TF-IDF features: 30\n",
      "Total text features: 80\n",
      "NaNs in text features: 0\n"
     ]
    }
   ],
   "source": [
    "# 1. Combined features TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=50,  # Reduced to avoid memory issues\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "# Ensure no NaN values in text\n",
    "combined_text = df_clean['combined_features'].fillna('no_features')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(combined_text)\n",
    "\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns=['tfidf_combined_' + str(i) for i in range(tfidf_matrix.shape[1])],\n",
    "    index=df_clean.index\n",
    ")\n",
    "\n",
    "# 2. Review text TF-IDF (separate)\n",
    "tfidf_reviews = TfidfVectorizer(\n",
    "    max_features=30,  # Smaller for reviews\n",
    "    stop_words='english',\n",
    "    min_df=3,\n",
    "    max_df=0.9\n",
    ")\n",
    "\n",
    "review_text = df_clean['review_text'].fillna('no_review')\n",
    "review_matrix = tfidf_reviews.fit_transform(review_text)\n",
    "\n",
    "review_df = pd.DataFrame(\n",
    "    review_matrix.toarray(),\n",
    "    columns=['tfidf_review_' + str(i) for i in range(review_matrix.shape[1])],\n",
    "    index=df_clean.index\n",
    ")\n",
    "\n",
    "# Combine text features\n",
    "text_features_combined = pd.concat([tfidf_df, review_df], axis=1)\n",
    "\n",
    "print(\"=== TEXT VECTORIZATION COMPLETE ===\")\n",
    "print(f\"Combined TF-IDF features: {tfidf_df.shape[1]}\")\n",
    "print(f\"Review TF-IDF features: {review_df.shape[1]}\")\n",
    "print(f\"Total text features: {text_features_combined.shape[1]}\")\n",
    "print(f\"NaNs in text features: {text_features_combined.isna().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54150d2c",
   "metadata": {},
   "source": [
    "### Create Final Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7faa436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL FEATURE MATRICES ===\n",
      "Content features shape: (31030, 257)\n",
      "Text features shape: (31030, 82)\n",
      "Hybrid features shape: (31030, 58)\n",
      "Basic info shape: (31030, 9)\n",
      "\n",
      "NaN CHECK:\n",
      "NaNs in content_features: 0\n",
      "NaNs in text_based_features: 0\n",
      "NaNs in hybrid_features: 0\n",
      "NaNs in basic_info: 0\n",
      "\n",
      "AFTER FINAL CLEANUP:\n",
      "NaNs in content_features: 0\n",
      "NaNs in text_based_features: 0\n",
      "NaNs in hybrid_features: 0\n"
     ]
    }
   ],
   "source": [
    "# 1. Numerical features (already scaled and imputed)\n",
    "numerical_features = df_clean[['rating_imputed_scaled', 'cost_imputed_scaled', \n",
    "                                'log_votes_scaled', 'popularity_score_scaled']].copy()\n",
    "\n",
    "# 2. Content-based features\n",
    "content_features = pd.concat([\n",
    "    numerical_features,\n",
    "    service_features,\n",
    "    location_encoded,\n",
    "    rest_type_encoded,\n",
    "    cuisine_df\n",
    "], axis=1)\n",
    "\n",
    "# 3. Text-based features\n",
    "text_based_features = pd.concat([\n",
    "    numerical_features[['rating_imputed_scaled', 'popularity_score_scaled']],  # Basic context\n",
    "    text_features_combined\n",
    "], axis=1)\n",
    "\n",
    "# 4. Hybrid features (combination of all)\n",
    "hybrid_features = pd.concat([\n",
    "    numerical_features,\n",
    "    service_features,\n",
    "    location_encoded.iloc[:, :10],  # Top 10 locations to control size\n",
    "    rest_type_encoded.iloc[:, :5],   # Top 5 restaurant types\n",
    "    cuisine_df.iloc[:, :15],         # Top 15 cuisines\n",
    "    text_features_combined.iloc[:, :20]       # Top 20 text features\n",
    "], axis=1)\n",
    "\n",
    "# 5. Basic info for reference\n",
    "basic_info = df_clean[['name', 'address', 'location', 'cuisines', \n",
    "                        'rating_imputed', 'cost_imputed', 'rest_type', \n",
    "                        'online_order', 'book_table']].copy()\n",
    "\n",
    "# Rename columns for clarity\n",
    "basic_info = basic_info.rename(columns={\n",
    "    'rating_imputed': 'rating',\n",
    "    'cost_imputed': 'cost_for_two'\n",
    "})\n",
    "\n",
    "# Final verification - check for NaNs\n",
    "print(\"=== FINAL FEATURE MATRICES ===\")\n",
    "print(f\"Content features shape: {content_features.shape}\")\n",
    "print(f\"Text features shape: {text_based_features.shape}\")\n",
    "print(f\"Hybrid features shape: {hybrid_features.shape}\")\n",
    "print(f\"Basic info shape: {basic_info.shape}\")\n",
    "\n",
    "print(f\"\\nNaN CHECK:\")\n",
    "print(f\"NaNs in content_features: {content_features.isna().sum().sum()}\")\n",
    "print(f\"NaNs in text_based_features: {text_based_features.isna().sum().sum()}\")\n",
    "print(f\"NaNs in hybrid_features: {hybrid_features.isna().sum().sum()}\")\n",
    "print(f\"NaNs in basic_info: {basic_info.isna().sum().sum()}\")\n",
    "\n",
    "# Final cleanup - replace any remaining NaNs with 0\n",
    "content_features = content_features.fillna(0)\n",
    "text_based_features = text_based_features.fillna(0)\n",
    "hybrid_features = hybrid_features.fillna(0)\n",
    "\n",
    "print(f\"\\nAFTER FINAL CLEANUP:\")\n",
    "print(f\"NaNs in content_features: {content_features.isna().sum().sum()}\")\n",
    "print(f\"NaNs in text_based_features: {text_based_features.isna().sum().sum()}\")\n",
    "print(f\"NaNs in hybrid_features: {hybrid_features.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6f9ef7",
   "metadata": {},
   "source": [
    "### Saving Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72de530b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering complete! Files saved:\n",
      "- ../processed_data/processed_restaurant_data.csv\n",
      "- ../processed_data/content_features.csv\n",
      "- ../processed_data/text_features.csv\n",
      "- ../processed_data/hybrid_features.csv\n",
      "- ../models/feature_scaler.pkl\n",
      "- ../models/tfidf_vectorizer.pkl\n",
      "- ../models/cuisine_encoder.pkl\n",
      "\n",
      "=== FINAL SUMMARY ===\n",
      "Total restaurants processed: 31030\n",
      "Content features: 257 dimensions\n",
      "Text features: 80 dimensions\n",
      "Hybrid features: 58 dimensions\n",
      "All features are NaN-free and ready for modeling!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create nested directories (e.g., parent/child/grandchild)\n",
    "processed_data = \"../processed_data\"\n",
    "model_path = \"../models\"\n",
    "os.makedirs(processed_data, exist_ok=True)\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "# Save all processed data\n",
    "basic_info.to_csv(f'{processed_data}/processed_restaurant_data.csv', index=False)\n",
    "content_features.to_csv(f'{processed_data}/content_features.csv', index=False)\n",
    "text_features_combined.to_csv(f'{processed_data}/text_features.csv', index=False)\n",
    "hybrid_features.to_csv(f'{processed_data}/hybrid_features.csv', index=False)\n",
    "\n",
    "# Save encoders and transformers\n",
    "import pickle\n",
    "\n",
    "with open(f'{model_path}/feature_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_scaler, f)\n",
    "\n",
    "with open(f'{model_path}/tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "\n",
    "with open(f'{model_path}/cuisine_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(cuisine_encoder, f)\n",
    "\n",
    "print(\"Feature engineering complete! Files saved:\")\n",
    "print(f\"- {processed_data}/processed_restaurant_data.csv\")\n",
    "print(f\"- {processed_data}/content_features.csv\")\n",
    "print(f\"- {processed_data}/text_features.csv\") \n",
    "print(f\"- {processed_data}/hybrid_features.csv\")\n",
    "print(f\"- {model_path}/feature_scaler.pkl\")\n",
    "print(f\"- {model_path}/tfidf_vectorizer.pkl\")\n",
    "print(f\"- {model_path}/cuisine_encoder.pkl\")\n",
    "\n",
    "# Display final summary\n",
    "print(f\"\\n=== FINAL SUMMARY ===\")\n",
    "print(f\"Total restaurants processed: {len(basic_info)}\")\n",
    "print(f\"Content features: {content_features.shape[1]} dimensions\")\n",
    "print(f\"Text features: {text_features_combined.shape[1]} dimensions\") \n",
    "print(f\"Hybrid features: {hybrid_features.shape[1]} dimensions\")\n",
    "print(f\"All features are NaN-free and ready for modeling!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff74d880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommendation-system (3.11.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
