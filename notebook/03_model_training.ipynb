{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da2c03b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADED ===\n",
      "Restaurants: 15515\n",
      "Feature dimensions: 298\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load processed data\n",
    "df_clean = pd.read_csv('processed_restaurant_data.csv')\n",
    "similarity_features = pd.read_csv('similarity_features.csv')\n",
    "content_features = pd.read_csv('content_features.csv')\n",
    "text_features = pd.read_csv('text_features.csv')\n",
    "hybrid_features = pd.read_csv('hybrid_features.csv')\n",
    "\n",
    "print(\"=== DATA LOADED ===\")\n",
    "print(f\"Restaurants: {len(df_clean)}\")\n",
    "print(f\"Feature dimensions: {similarity_features.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64ee5742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in similarity_features: 3222870\n",
      "NaNs in content_features: 2119740\n",
      "NaNs in text_features: 1103130\n",
      "NaNs in hybrid_features: 3222870\n"
     ]
    }
   ],
   "source": [
    "print(\"NaNs in similarity_features:\", similarity_features.isna().sum().sum())\n",
    "print(\"NaNs in content_features:\", content_features.isna().sum().sum())\n",
    "print(\"NaNs in text_features:\", text_features.isna().sum().sum())\n",
    "print(\"NaNs in hybrid_features:\", hybrid_features.isna().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "effe971d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating_scaled        10815\n",
       "popularity_scaled    10815\n",
       "tfidf_0              10815\n",
       "tfidf_1              10815\n",
       "tfidf_2              10815\n",
       "                     ...  \n",
       "tfidf_95             10815\n",
       "tfidf_96             10815\n",
       "tfidf_97             10815\n",
       "tfidf_98             10815\n",
       "tfidf_99             10815\n",
       "Length: 102, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature_matrix = feature_matrix.fillna(0)   # replace\n",
    "\n",
    "text_features.isnull().sum()  # check for NaN values in text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad50ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url                               0\n",
       "address                           0\n",
       "name                              0\n",
       "online_order                      0\n",
       "book_table                        0\n",
       "rate                           2347\n",
       "votes                             0\n",
       "phone                           389\n",
       "location                          0\n",
       "rest_type                         0\n",
       "dish_liked                     8426\n",
       "cuisines                          0\n",
       "approx_cost(for two people)     115\n",
       "reviews_list                      0\n",
       "menu_item                         0\n",
       "listed_in(type)                   0\n",
       "listed_in(city)                   0\n",
       "rating                            0\n",
       "cost_for_two                      0\n",
       "phone_clean                       0\n",
       "cuisine_list                      0\n",
       "dish_list                         0\n",
       "combined_features                 0\n",
       "review_text                    2311\n",
       "online_order_binary               0\n",
       "book_table_binary                 0\n",
       "location_grouped                  0\n",
       "rest_type_grouped                 0\n",
       "price_category                    0\n",
       "rating_category                   0\n",
       "rating_votes_ratio                0\n",
       "cost_per_rating                   0\n",
       "popularity_score                  0\n",
       "rating_scaled                     0\n",
       "cost_scaled                       0\n",
       "votes_scaled                      0\n",
       "ratio_scaled                      0\n",
       "popularity_scaled                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff540937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.9, 2.8, 3.8, 3.5, 3.2, 3.7, 4.2, 3.4, 2.9, 3.6, 3. , 4.3, 4.1,\n",
       "       3.3, 3.1, 4.4, 4.5, 4. , 4.6, 2.7, 2.6, 4.7, 4.9, 2.5, 4.8, 2.3,\n",
       "       2.4, 2.2, 2.1, 1.8, 2. ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.rating.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "911e2a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RestaurantRecommender:\n",
    "    def __init__(self, restaurant_data, feature_matrix, similarity_metric='cosine'):\n",
    "        \"\"\"\n",
    "        Initialize the recommender system\n",
    "        \n",
    "        Args:\n",
    "            restaurant_data: DataFrame with restaurant information\n",
    "            feature_matrix: DataFrame with features for similarity calculation\n",
    "            similarity_metric: 'cosine', 'euclidean', or 'knn'\n",
    "        \"\"\"\n",
    "        self.restaurant_data = restaurant_data.reset_index(drop=True)\n",
    "        self.feature_matrix = feature_matrix.reset_index(drop=True)\n",
    "        self.similarity_metric = similarity_metric\n",
    "        \n",
    "        # Create restaurant name to index mapping\n",
    "        self.name_to_idx = {name: idx for idx, name in enumerate(self.restaurant_data['name'])}\n",
    "        \n",
    "        # Precompute similarity matrix\n",
    "        self._compute_similarity_matrix()\n",
    "        \n",
    "    def _compute_similarity_matrix(self):\n",
    "        \"\"\"Compute similarity matrix based on chosen metric\"\"\"\n",
    "        print(f\"Computing {self.similarity_metric} similarity matrix...\")\n",
    "        \n",
    "        if self.similarity_metric == 'cosine':\n",
    "            self.similarity_matrix = cosine_similarity(self.feature_matrix)\n",
    "        \n",
    "        elif self.similarity_metric == 'euclidean':\n",
    "            distances = euclidean_distances(self.feature_matrix)\n",
    "            # Convert distances to similarities (higher = more similar)\n",
    "            max_distance = distances.max()\n",
    "            self.similarity_matrix = 1 - (distances / max_distance)\n",
    "        \n",
    "        elif self.similarity_metric == 'knn':\n",
    "            # Use KNN for similarity\n",
    "            self.knn_model = NearestNeighbors(\n",
    "                n_neighbors=50, \n",
    "                metric='cosine', \n",
    "                algorithm='brute'\n",
    "            )\n",
    "            self.knn_model.fit(self.feature_matrix)\n",
    "            self.similarity_matrix = None  # Will compute on-demand\n",
    "        \n",
    "        print(f\"Similarity computation complete!\")\n",
    "    \n",
    "    def get_restaurant_index(self, restaurant_name):\n",
    "        \"\"\"Get restaurant index by name\"\"\"\n",
    "        if restaurant_name not in self.name_to_idx:\n",
    "            # Fuzzy matching\n",
    "            possible_matches = [name for name in self.name_to_idx.keys() \n",
    "                              if restaurant_name.lower() in name.lower()]\n",
    "            if possible_matches:\n",
    "                return self.name_to_idx[possible_matches[0]]\n",
    "            else:\n",
    "                raise ValueError(f\"Restaurant '{restaurant_name}' not found!\")\n",
    "        return self.name_to_idx[restaurant_name]\n",
    "    \n",
    "    def get_recommendations(self, restaurant_name, n_recommendations=10, \n",
    "                          include_similar_cuisine=True, include_similar_location=True):\n",
    "        \"\"\"\n",
    "        Get restaurant recommendations\n",
    "        \n",
    "        Args:\n",
    "            restaurant_name: Name of the reference restaurant\n",
    "            n_recommendations: Number of recommendations to return\n",
    "            include_similar_cuisine: Whether to boost similar cuisine restaurants\n",
    "            include_similar_location: Whether to boost same location restaurants\n",
    "        \"\"\"\n",
    "        try:\n",
    "            restaurant_idx = self.get_restaurant_index(restaurant_name)\n",
    "        except ValueError as e:\n",
    "            return str(e)\n",
    "        \n",
    "        if self.similarity_metric == 'knn':\n",
    "            # Use KNN for recommendations\n",
    "            distances, indices = self.knn_model.kneighbors(\n",
    "                [self.feature_matrix.iloc[restaurant_idx]], \n",
    "                n_neighbors=n_recommendations+1\n",
    "            )\n",
    "            # Remove the restaurant itself (first result)\n",
    "            recommended_indices = indices[0][1:]\n",
    "            similarity_scores = 1 - distances[0][1:]  # Convert distances to similarities\n",
    "        else:\n",
    "            # Use precomputed similarity matrix\n",
    "            similarity_scores = self.similarity_matrix[restaurant_idx]\n",
    "            \n",
    "            # Apply filters and boosts\n",
    "            if include_similar_cuisine or include_similar_location:\n",
    "                similarity_scores = self._apply_filters_and_boosts(\n",
    "                    restaurant_idx, similarity_scores, \n",
    "                    include_similar_cuisine, include_similar_location\n",
    "                )\n",
    "            \n",
    "            # Get top similar restaurants (excluding the restaurant itself)\n",
    "            similar_indices = np.argsort(similarity_scores)[::-1]\n",
    "            recommended_indices = [idx for idx in similar_indices if idx != restaurant_idx][:n_recommendations]\n",
    "            similarity_scores = similarity_scores[recommended_indices]\n",
    "        \n",
    "        # Create recommendations DataFrame\n",
    "        recommendations = self.restaurant_data.iloc[recommended_indices].copy()\n",
    "        recommendations['similarity_score'] = similarity_scores[:len(recommended_indices)]\n",
    "        \n",
    "        # Select relevant columns\n",
    "        columns_to_show = [\n",
    "            'name', 'cuisines', 'location', 'rating', 'cost_for_two', \n",
    "            'rest_type', 'online_order', 'book_table', 'similarity_score'\n",
    "        ]\n",
    "        \n",
    "        available_columns = [col for col in columns_to_show if col in recommendations.columns]\n",
    "        recommendations = recommendations[available_columns]\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def _apply_filters_and_boosts(self, restaurant_idx, similarity_scores, \n",
    "                                 include_similar_cuisine, include_similar_location):\n",
    "        \"\"\"Apply cuisine and location boosts to similarity scores\"\"\"\n",
    "        reference_restaurant = self.restaurant_data.iloc[restaurant_idx]\n",
    "        \n",
    "        if include_similar_cuisine:\n",
    "            # Boost restaurants with similar cuisines\n",
    "            reference_cuisines = set(str(reference_restaurant['cuisines']).lower().split(', '))\n",
    "            for idx in range(len(similarity_scores)):\n",
    "                if idx != restaurant_idx:\n",
    "                    restaurant_cuisines = set(str(self.restaurant_data.iloc[idx]['cuisines']).lower().split(', '))\n",
    "                    cuisine_overlap = len(reference_cuisines.intersection(restaurant_cuisines))\n",
    "                    if cuisine_overlap > 0:\n",
    "                        similarity_scores[idx] *= (1 + 0.2 * cuisine_overlap)  # 20% boost per overlapping cuisine\n",
    "        \n",
    "        if include_similar_location:\n",
    "            # Boost restaurants in the same location\n",
    "            reference_location = reference_restaurant['location']\n",
    "            for idx in range(len(similarity_scores)):\n",
    "                if idx != restaurant_idx:\n",
    "                    if self.restaurant_data.iloc[idx]['location'] == reference_location:\n",
    "                        similarity_scores[idx] *= 1.3  # 30% boost for same location\n",
    "        \n",
    "        return similarity_scores\n",
    "    \n",
    "    def get_restaurant_details(self, restaurant_name):\n",
    "        \"\"\"Get detailed information about a restaurant\"\"\"\n",
    "        try:\n",
    "            restaurant_idx = self.get_restaurant_index(restaurant_name)\n",
    "            return self.restaurant_data.iloc[restaurant_idx]\n",
    "        except ValueError as e:\n",
    "            return str(e)\n",
    "    \n",
    "    def find_similar_restaurants_by_criteria(self, cuisine=None, location=None, \n",
    "                                           price_range=None, rating_min=None, n_results=20):\n",
    "        \"\"\"Find restaurants based on specific criteria\"\"\"\n",
    "        filtered_data = self.restaurant_data.copy()\n",
    "        \n",
    "        # Apply filters\n",
    "        if cuisine:\n",
    "            filtered_data = filtered_data[\n",
    "                filtered_data['cuisines'].str.contains(cuisine, case=False, na=False)\n",
    "            ]\n",
    "        \n",
    "        if location:\n",
    "            filtered_data = filtered_data[\n",
    "                filtered_data['location'].str.contains(location, case=False, na=False)\n",
    "            ]\n",
    "        \n",
    "        if price_range:\n",
    "            if price_range == 'budget':\n",
    "                filtered_data = filtered_data[filtered_data['cost_for_two'] <= 300]\n",
    "            elif price_range == 'mid':\n",
    "                filtered_data = filtered_data[\n",
    "                    (filtered_data['cost_for_two'] > 300) & (filtered_data['cost_for_two'] <= 600)\n",
    "                ]\n",
    "            elif price_range == 'expensive':\n",
    "                filtered_data = filtered_data[filtered_data['cost_for_two'] > 600]\n",
    "        \n",
    "        if rating_min:\n",
    "            filtered_data = filtered_data[filtered_data['rating'] >= rating_min]\n",
    "        \n",
    "        # Sort by rating and popularity\n",
    "        filtered_data = filtered_data.sort_values(['rating', 'votes'], ascending=[False, False])\n",
    "        \n",
    "        return filtered_data.head(n_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e28bfc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentBasedRecommender(RestaurantRecommender):\n",
    "    \"\"\"Recommender based on restaurant content features (cuisine, location, price, etc.)\"\"\"\n",
    "    \n",
    "    def __init__(self, restaurant_data, feature_matrix):\n",
    "        super().__init__(restaurant_data, feature_matrix, similarity_metric='cosine')\n",
    "        \n",
    "    def get_cuisine_based_recommendations(self, restaurant_name, n_recommendations=10):\n",
    "        \"\"\"Get recommendations based primarily on cuisine similarity\"\"\"\n",
    "        return self.get_recommendations(\n",
    "            restaurant_name, n_recommendations, \n",
    "            include_similar_cuisine=True, include_similar_location=False\n",
    "        )\n",
    "    \n",
    "    def get_location_based_recommendations(self, restaurant_name, n_recommendations=10):\n",
    "        \"\"\"Get recommendations based primarily on location similarity\"\"\"\n",
    "        return self.get_recommendations(\n",
    "            restaurant_name, n_recommendations,\n",
    "            include_similar_cuisine=False, include_similar_location=True\n",
    "        )\n",
    "\n",
    "\n",
    "class TextBasedRecommender(RestaurantRecommender):\n",
    "    \"\"\"Recommender based on text features (reviews, dishes, descriptions)\"\"\"\n",
    "    \n",
    "    def __init__(self, restaurant_data, feature_matrix):\n",
    "        super().__init__(restaurant_data, feature_matrix, similarity_metric='cosine')\n",
    "\n",
    "\n",
    "class HybridRecommender:\n",
    "    \"\"\"Hybrid recommender combining multiple approaches\"\"\"\n",
    "    \n",
    "    def __init__(self, restaurant_data, content_features, text_features):\n",
    "        self.restaurant_data = restaurant_data\n",
    "        \n",
    "        # Initialize individual recommenders\n",
    "        self.content_recommender = ContentBasedRecommender(restaurant_data, content_features)\n",
    "        self.text_recommender = TextBasedRecommender(restaurant_data, text_features)\n",
    "        \n",
    "        # Weights for different recommendation types\n",
    "        self.weights = {\n",
    "            'content': 0.6,\n",
    "            'text': 0.4\n",
    "        }\n",
    "    \n",
    "    def get_hybrid_recommendations(self, restaurant_name, n_recommendations=10):\n",
    "        \"\"\"Get recommendations using hybrid approach\"\"\"\n",
    "        \n",
    "        # Get recommendations from both approaches\n",
    "        content_recs = self.content_recommender.get_recommendations(\n",
    "            restaurant_name, n_recommendations * 2\n",
    "        )\n",
    "        text_recs = self.text_recommender.get_recommendations(\n",
    "            restaurant_name, n_recommendations * 2\n",
    "        )\n",
    "        \n",
    "        if isinstance(content_recs, str) or isinstance(text_recs, str):\n",
    "            return \"Restaurant not found!\"\n",
    "        \n",
    "        # Combine and weight scores\n",
    "        combined_scores = {}\n",
    "        \n",
    "        # Process content-based recommendations\n",
    "        for idx, row in content_recs.iterrows():\n",
    "            restaurant_name_rec = row['name']\n",
    "            score = row['similarity_score'] * self.weights['content']\n",
    "            combined_scores[restaurant_name_rec] = combined_scores.get(restaurant_name_rec, 0) + score\n",
    "        \n",
    "        # Process text-based recommendations\n",
    "        for idx, row in text_recs.iterrows():\n",
    "            restaurant_name_rec = row['name']\n",
    "            score = row['similarity_score'] * self.weights['text']\n",
    "            combined_scores[restaurant_name_rec] = combined_scores.get(restaurant_name_rec, 0) + score\n",
    "        \n",
    "        # Sort by combined score\n",
    "        sorted_restaurants = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Get top N recommendations\n",
    "        top_restaurant_names = [name for name, score in sorted_restaurants[:n_recommendations]]\n",
    "        \n",
    "        # Create final recommendations DataFrame\n",
    "        final_recommendations = []\n",
    "        for name in top_restaurant_names:\n",
    "            restaurant_info = self.restaurant_data[self.restaurant_data['name'] == name].iloc[0]\n",
    "            final_recommendations.append({\n",
    "                'name': restaurant_info['name'],\n",
    "                'cuisines': restaurant_info['cuisines'],\n",
    "                'location': restaurant_info['location'],\n",
    "                'rating': restaurant_info['rating'],\n",
    "                'cost_for_two': restaurant_info['cost_for_two'],\n",
    "                'rest_type': restaurant_info['rest_type'],\n",
    "                'online_order': restaurant_info['online_order'],\n",
    "                'book_table': restaurant_info['book_table'],\n",
    "                'hybrid_score': combined_scores[name]\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(final_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa295126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating_scaled                        10815\n",
       "cost_scaled                          10815\n",
       "online_order_binary                  10815\n",
       "book_table_binary                    10815\n",
       "cuisine_afghan                       10815\n",
       "                                     ...  \n",
       "rest_type_Quick Bites                10815\n",
       "rest_type_Sweet Shop                 10815\n",
       "rest_type_Sweet Shop, Quick Bites    10815\n",
       "rest_type_Takeaway                   10815\n",
       "rest_type_Takeaway, Delivery         10815\n",
       "Length: 196, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_features.isnull().sum()  # Check for NaN values in content features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1da6f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INITIALIZING RECOMMENDERS ===\n",
      "Computing cosine similarity matrix...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Initialize all recommenders\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== INITIALIZING RECOMMENDERS ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m content_recommender = \u001b[43mContentBasedRecommender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m text_recommender = TextBasedRecommender(df_clean, text_features)\n\u001b[32m      6\u001b[39m hybrid_recommender = HybridRecommender(df_clean, content_features, text_features)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mContentBasedRecommender.__init__\u001b[39m\u001b[34m(self, restaurant_data, feature_matrix)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, restaurant_data, feature_matrix):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrestaurant_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcosine\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mRestaurantRecommender.__init__\u001b[39m\u001b[34m(self, restaurant_data, feature_matrix, similarity_metric)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mself\u001b[39m.name_to_idx = {name: idx \u001b[38;5;28;01mfor\u001b[39;00m idx, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.restaurant_data[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m])}\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Precompute similarity matrix\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_similarity_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mRestaurantRecommender._compute_similarity_matrix\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mComputing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.similarity_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m similarity matrix...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.similarity_metric == \u001b[33m'\u001b[39m\u001b[33mcosine\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[38;5;28mself\u001b[39m.similarity_matrix = \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.similarity_metric == \u001b[33m'\u001b[39m\u001b[33meuclidean\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     29\u001b[39m     distances = euclidean_distances(\u001b[38;5;28mself\u001b[39m.feature_matrix)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\development\\Recommendation_System\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\development\\Recommendation_System\\.venv\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1728\u001b[39m, in \u001b[36mcosine_similarity\u001b[39m\u001b[34m(X, Y, dense_output)\u001b[39m\n\u001b[32m   1675\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m   1676\u001b[39m     {\n\u001b[32m   1677\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msparse matrix\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1682\u001b[39m )\n\u001b[32m   1683\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcosine_similarity\u001b[39m(X, Y=\u001b[38;5;28;01mNone\u001b[39;00m, dense_output=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   1684\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[32m   1685\u001b[39m \n\u001b[32m   1686\u001b[39m \u001b[33;03m    Cosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1726\u001b[39m \u001b[33;03m           [0.577, 0.816]])\u001b[39;00m\n\u001b[32m   1727\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1728\u001b[39m     X, Y = \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1730\u001b[39m     X_normalized = normalize(X, copy=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1731\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\development\\Recommendation_System\\.venv\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:190\u001b[39m, in \u001b[36mcheck_pairwise_arrays\u001b[39m\u001b[34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_all_finite, ensure_2d, copy)\u001b[39m\n\u001b[32m    187\u001b[39m     dtype = dtype_float\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m X \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     X = Y = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    200\u001b[39m     X = check_array(\n\u001b[32m    201\u001b[39m         X,\n\u001b[32m    202\u001b[39m         accept_sparse=accept_sparse,\n\u001b[32m   (...)\u001b[39m\u001b[32m    207\u001b[39m         ensure_2d=ensure_2d,\n\u001b[32m    208\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\development\\Recommendation_System\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1105\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1102\u001b[39m     )\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1114\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\development\\Recommendation_System\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\development\\Recommendation_System\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "# Initialize all recommenders\n",
    "print(\"=== INITIALIZING RECOMMENDERS ===\")\n",
    "\n",
    "content_recommender = ContentBasedRecommender(df_clean, content_features)\n",
    "text_recommender = TextBasedRecommender(df_clean, text_features)\n",
    "hybrid_recommender = HybridRecommender(df_clean, content_features, text_features)\n",
    "\n",
    "print(\"All recommenders initialized successfully!\")\n",
    "\n",
    "# Test with a sample restaurant\n",
    "sample_restaurant = df_clean['name'].iloc[0]\n",
    "print(f\"\\nTesting with restaurant: {sample_restaurant}\")\n",
    "\n",
    "# Test content-based recommendations\n",
    "print(\"\\n=== CONTENT-BASED RECOMMENDATIONS ===\")\n",
    "content_recs = content_recommender.get_recommendations(sample_restaurant, 5)\n",
    "print(content_recs[['name', 'cuisines', 'location', 'rating', 'similarity_score']])\n",
    "\n",
    "# Test text-based recommendations\n",
    "print(\"\\n=== TEXT-BASED RECOMMENDATIONS ===\")\n",
    "text_recs = text_recommender.get_recommendations(sample_restaurant, 5)\n",
    "print(text_recs[['name', 'cuisines', 'location', 'rating', 'similarity_score']])\n",
    "\n",
    "# Test hybrid recommendations\n",
    "print(\"\\n=== HYBRID RECOMMENDATIONS ===\")\n",
    "hybrid_recs = hybrid_recommender.get_hybrid_recommendations(sample_restaurant, 5)\n",
    "print(hybrid_recs[['name', 'cuisines', 'location', 'rating', 'hybrid_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72aa290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommendation-system (3.11.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
